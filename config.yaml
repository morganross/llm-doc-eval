fpf:
  path: ''
llm_api:
  max_concurrent_llm_calls: 32
  timeout_seconds: 120
retries:
  attempts: 3
  base_delay_seconds: 2
  max_delay_seconds: 10
  jitter: true
judge_defaults:
  temperature: 0.0
  max_tokens: 24096
  enable_grounding: true
models:
  google_gemini-2.5-pro:
    provider: google
    model: gemini-2.5-pro
  openai_gpt-5:
    provider: openai
    model: gpt-5
single_doc_eval:
  trial_count: 1
  criteria_file: criteria.yaml
pairwise_eval:
  trial_count: 1
  criteria_file: criteria.yaml
evaluation:
  mode: both
jsonify:
  enabled: true
  provider: openai
  model: gpt-4o-mini
  temperature: 0.1
  max_output_tokens: 500
